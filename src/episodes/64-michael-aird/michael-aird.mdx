---
number: "64"
path: "/episodes/aird-ai"
date: "2023-06-07"
title: "Michael Aird on Strategies for Reducing AI Existential Risk"
audio: "https://pinecast.com/listen/42b8cd89-4a86-43f1-b5a3-7e0f8667e5c1.mp3"
featuredImage: "images/michael-share.png"
backgroundImage: "images/bg4.png"
apple: ""
spotify: ""
google: ""
status: "live"
---

Michael Aird is a senior research manager at [Rethink Priorities](https://www.rethinkpriorities.org/), where he co-leads the Artificial Intelligence Governance and Strategy team alongside Amanda El-Dakhakhni. Before that he conducted nuclear risk research for Rethink Priorities and longtermist macrostrategy research for [Convergence Analysis](https://www.convergenceanalysis.org/), the [Center on Long-Term Risk](https://longtermrisk.org/), and the [Future of Humanity Institute](https://www.fhi.ox.ac.uk/). Before that, he was a teacher and a stand up comedian.

Michael previously spoke to us about impact-driven research on [Episode 52](https://hearthisidea.com/episodes/aird).

*Note: Rethink Priorities is [hiring for a Compute Governance Researcher or Research Assistant](https://careers.rethinkpriorities.org/en/postings/f553d816-53ef-40e6-84bb-257d550ec52b)! Applications close June 12, 2023.*

<div class="episode-image_variable episode-image_smaller">

![Michael Aird](images/michael.png)

</div>

In this episode we talk about:

* The basic case for working on existential risk from AI
* How to begin figuring out what to do to reduce the risks
  * Is there a 'plan' yet?
  * Are there frameworks we can use to get clearer on paths forward?
  * Threat models for the risks of advanced AI
  * 'Theories of victory' for how the world mitigates the risks
* 'Intermediate goals' in AI governance
  * The results of Rethink Priority's recent [expert survey on intermediate goals](https://forum.effectivealtruism.org/posts/g4fXhiJyj6tdBhuBK/survey-on-intermediate-goals-in-ai-governance)
* What useful (and less useful) research looks like for reducing AI x-risk
* Practical advice for usefully contributing to efforts to reduce existential risk from AI
  * Resources for getting started and finding job openings


## Michael's recommended reading

* [The "most important century" blog post series](https://www.cold-takes.com/most-important-century/) by Holden Karnofsky
  * You can find an audio version at [Cold Takes Audio](https://podcasts.apple.com/us/podcast/cold-takes-audio/id1580097837)
* [The longtermist AI governance landscape: a basic overview](https://forum.effectivealtruism.org/posts/ydpo7LcJWhrr2GJrx/the-longtermist-ai-governance-landscape-a-basic-overview) by Sam Clarke
* [AI Safety Fundamentals](https://aisafetyfundamentals.com/) — [Governance course](https://aisafetyfundamentals.com/ai-governance-curriculum)
* Audio versions of writing on AI governance and related topics can be found at —
  * The [LessWrong Curated Podcast](https://www.lesswrong.com/posts/kDjKF2yFhFEWe4hgC/announcing-the-lesswrong-curated-podcast)
  * The [EA Forum audio feeds](https://forum.effectivealtruism.org/posts/K5Snxo5EhgmwJJjR2/announcing-ea-forum-podcast-audio-narrations-of-ea-forum)
  * The [Nonlinear Library](https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library)

![Michael Aird](images/bg3.png)

## Further reading

* [Rethink Priorities](https://rethinkpriorities.org/) website
  * Rethink Priority's [survey on intermediate goals in AI governance](https://forum.effectivealtruism.org/posts/g4fXhiJyj6tdBhuBK/survey-on-intermediate-goals-in-ai-governance)
* The [Centre of the Governance of AI](https://www.governance.ai/) (newsletter available on the homepage)
* ['What Failure Looks Like'](https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like) by Paul Christiano
* [Some AI Governance Research Ideas](https://docs.google.com/document/d/13LJhP3ksrcEBKxYFG5GkJaC2UoxHKUYAHCRdRlpePEc/edit#) compiled by Markus Anderljung & Alexis Carlier
* [Strategic Perspectives on Long-term AI Governance](https://forum.effectivealtruism.org/s/xTkejiJHFsidZ9hMo) by Matthijs Maas 
* [Michael's posts on the Effective Altruism Forum](https://forum.effectivealtruism.org/users/michaela) (under the username "MichaelA")
* The [80,000 Hours job board](https://jobs.80000hours.org/)
* EA funding opportunities —
  * [Don’t think, just apply! (usually)](https://forum.effectivealtruism.org/posts/Fahv9knHhPi6pWPEB/don-t-think-just-apply-usually)
  * [List of EA funding opportunities](https://forum.effectivealtruism.org/posts/DqwxrdyQxcMQ8P2rD/list-of-ea-funding-opportunities)
  * [Why YOU should consider applying for funding](https://docs.google.com/presentation/d/1awjq4A-262EzV8BY5IXxnDcaB5oBZCIf7rF4QUXV0T0/edit#slide=id.p)
* The [Rethink Priorities newsletter](https://rethinkpriorities.org/newsletter)
* The [Rethink Priorities tab](https://forum.effectivealtruism.org/topics/rethink-priorities) on the Effective Altruism Forum

## Transcript

*Coming soon!*

![Michael Aird](images/bg2.png)
