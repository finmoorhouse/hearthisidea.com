---
number: "65"
path: "/episodes/grace"
date: "2023-06-10"
title: "Katja Grace on Slowing Down AI and Whether the X-Risk Case Holds Up"
audio: "https://pinecast.com/listen/a5127960-d4a7-40e7-9a58-6b9c607567a2.mp3"
featuredImage: "images/katja-share.png"
backgroundImage: "images/katja-bg.png"
apple: ""
spotify: ""
google: ""
status: "live"
---

[Katja Grace](https://katjagrace.com/) is a researcher and writer. She runs [AI Impacts](http://aiimpacts.org), a research project trying to incrementally answer decision-relevant questions about the future of artificial intelligence (AI).

Katja blogs primarily at [worldspiritsockpuppet](http://worldspiritsockpuppet.com/), and indirectly at [Meteuphoric](http://meteuphoric.wordpress.com/), [Worldly Positions](https://medium.com/worldly-positions), [LessWrong](https://www.lesswrong.com/users/katjagrace) and the [EA Forum](https://forum.effectivealtruism.org/users/katja_grace).

<div class="episode-image_variable episode-image_smaller">

![Katja Grace](images/katja-4.jpg)

</div>

In this episode we talk about:
* What is [AI Impacts](http://aiimpacts.org) working on?
* [Counterarguments to the basic AI x-risk case](https://www.lesswrong.com/posts/LDRQ5Zfqwi8GjzPYG/counterarguments-to-the-basic-ai-x-risk-case)
  * Reasons to doubt that superhuman AI systems will be strongly goal-directed
  * Reasons to doubt that if goal-directed superhuman AI systems are built, their goals will be bad by human lights
    * How [fragile is value](https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile), really?
    * Aren't deep learning systems fairly good at understanding our 'true' intentions?
  * Reasons to doubt that (misaligned) superhuman AI would be sufficiently superior to humans to overpower humanity
    * Would autonomous AI systems be radically more powerful than humans in combination with AI tools?
    * Is power-seeking always instrumentally useful?
  * Does the overall case for AI x-risk prove too much?
  * Why does Katja still worry about AI x-risk?
* The case for slowing down AI
  * Is AI really an arms race?
  * Wouldn't calls to slow down AI mostly affect the most conscientious actors?
  * Are there examples from history of valuable technologies being limited or slowed down?
  * What does Katja think about the recent [open letter on pausing giant AI experiments](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)?
* And more
  * Why don't [humans trade with ants](https://worldspiritsockpuppet.com/2023/01/10/we-dont-trade-with-ants.html)?
  * Have we really [forsaken natural selection](https://worldspiritsockpuppet.com/2023/01/11/have-we-foresaken-natural-selection.html)?
  * Why read [George Saunders](https://www.wikiwand.com/en/George_Saunders)?


## Katja's recommended reading
* [Is Power-Seeking AI an Existential Risk?](https://arxiv.org/abs/2206.13353) — Joe Carlsmith
  * Also [available in audio](https://forum.effectivealtruism.org/posts/yopb28oW9xb8jATjR/linkpost-human-narrated-audio-version-of-is-power-seeking-ai) and as a [short video presentation](https://forum.effectivealtruism.org/posts/ChuABPEXmRumcJY57/video-and-transcript-of-presentation-on-existential-risk)
* AI Impacts [research reports](https://aiimpacts.org/research-reports/) and [wiki](https://wiki.aiimpacts.org/)
  * (Not a Katja recommendation but we think you should check them out!)
## Further reading

- [AI Impacts](http://aiimpacts.org)
- [World Spirit Sock Puppet](https://worldspiritsockpuppet.com/) (Katja's main blog)

### AI x-risk

* [Counterarguments to the basic AI x-risk case](https://www.lesswrong.com/posts/LDRQ5Zfqwi8GjzPYG/counterarguments-to-the-basic-ai-x-risk-case) — Katja Grace
* [The Hidden Complexity of Wishes](https://www.lesswrong.com/posts/4ARaTpNX62uaL86j6/the-hidden-complexity-of-wishes) — Eliezer Yudkowsky
* [Value is fragile](https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile) — Eliezer Yudkowsky
* Katja [speaks with Robin Hanson about AI risk](https://www.youtube.com/watch?v=em0_p9eL_XE)

### Slowing down AI

- [Let's think about slowing down AI](https://worldspiritsockpuppet.substack.com/p/lets-think-about-slowing-down-ai) — Katja Grace
- [AI is Not an Arms Race](https://time.com/6283609/artificial-intelligence-race-existential-threat/) — Katja Grace
- [Pause Giant AI Experiments: An Open Letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) — Future of Life Institute

### More

- [We don't trade with ants](https://worldspiritsockpuppet.com/2023/01/10/we-dont-trade-with-ants.html) — Katja Grace
- [The Incredible Buddha Boy](https://www.gq.com/story/ram-bornjon-miracle-meditating) — George Saunders
- [Thank You, Esther Forbes](https://sherwoodenglishone.files.wordpress.com/2010/09/saundersforbesessay.pdf) — George Saunders

## Transcript

*Coming soon!*
